{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45087e59-580d-46fb-bcb6-a3509425bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils, segmentation, presentation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5059538-77c9-47db-8a92-0406f8197d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = segmentation.SegmentationDataset('./cut_stenoses_data/train/', 2)\n",
    "ds_test = segmentation.SegmentationDataset('./cut_stenoses_data/test/', 2)\n",
    "\n",
    "batch_size = 8\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bafe610-5b73-42c4-aa8d-7411f5859734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl_train), len(dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea7a0dd-d609-4c39-b539-8c71bb65bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dbde329-58a2-4808-8d8d-4526aee4f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = presentation.create_model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ebb2110-461d-4f16-b4fe-2b3211a47f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = presentation.create_optimizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05d6daaf-7481-427f-baf1-25d24c8294b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = 0.\n",
    "# for imgs, masks in dl_train:\n",
    "#     w += masks.sum() / (masks.numel() * len(dl_train))\n",
    "# loss_fn = nn.CrossEntropyLoss(weight=torch.Tensor([1 / (1-w), 1/ w])).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd5cda3c-6418-4cae-9941-ee6d61387532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0209 0.0159 tensor([0.])\n",
      "1 0.0065 0.0206 tensor([0.])\n",
      "2 0.0057 0.0200 tensor([0.0005])\n",
      "3 0.0051 0.0177 tensor([0.3104])\n",
      "4 0.0047 0.0179 tensor([0.3568])\n",
      "5 0.0043 0.0180 tensor([0.3893])\n",
      "6 0.0039 0.0200 tensor([0.3762])\n",
      "7 0.0037 0.0176 tensor([0.4148])\n",
      "8 0.0034 0.0165 tensor([0.4567])\n",
      "9 0.0032 0.0189 tensor([0.4302])\n",
      "10 0.0031 0.0190 tensor([0.4309])\n",
      "11 0.0030 0.0163 tensor([0.4740])\n",
      "12 0.0028 0.0192 tensor([0.4481])\n",
      "13 0.0026 0.0158 tensor([0.4978])\n",
      "14 0.0025 0.0181 tensor([0.4761])\n",
      "15 0.0024 0.0172 tensor([0.4919])\n",
      "16 0.0023 0.0165 tensor([0.5044])\n",
      "17 0.0022 0.0172 tensor([0.4988])\n",
      "18 0.0021 0.0185 tensor([0.4883])\n",
      "19 0.0021 0.0178 tensor([0.5000])\n",
      "20 0.0020 0.0183 tensor([0.5007])\n",
      "21 0.0019 0.0189 tensor([0.4982])\n",
      "22 0.0019 0.0161 tensor([0.5300])\n",
      "23 0.0018 0.0181 tensor([0.5162])\n",
      "24 0.0018 0.0163 tensor([0.5328])\n",
      "25 0.0017 0.0158 tensor([0.5378])\n",
      "26 0.0017 0.0157 tensor([0.5506])\n",
      "27 0.0016 0.0171 tensor([0.5302])\n",
      "28 0.0016 0.0163 tensor([0.5455])\n",
      "29 0.0015 0.0159 tensor([0.5463])\n",
      "30 0.0015 0.0160 tensor([0.5509])\n",
      "31 0.0015 0.0174 tensor([0.5358])\n",
      "32 0.0014 0.0173 tensor([0.5403])\n",
      "33 0.0014 0.0195 tensor([0.5210])\n",
      "34 0.0014 0.0166 tensor([0.5533])\n",
      "35 0.0013 0.0159 tensor([0.5620])\n",
      "36 0.0013 0.0184 tensor([0.5394])\n",
      "37 0.0013 0.0165 tensor([0.5559])\n",
      "38 0.0013 0.0166 tensor([0.5569])\n",
      "39 0.0012 0.0151 tensor([0.5737])\n",
      "40 0.0012 0.0162 tensor([0.5676])\n",
      "41 0.0012 0.0158 tensor([0.5763])\n",
      "42 0.0012 0.0185 tensor([0.5541])\n",
      "43 0.0012 0.0180 tensor([0.5594])\n",
      "44 0.0012 0.0175 tensor([0.5596])\n",
      "45 0.0011 0.0170 tensor([0.5675])\n",
      "46 0.0011 0.0162 tensor([0.5752])\n",
      "47 0.0011 0.0164 tensor([0.5738])\n",
      "48 0.0011 0.0162 tensor([0.5786])\n",
      "49 0.0011 0.0168 tensor([0.5682])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    trn_loss = utils.train(dl_train, loss_fn, model, optimizer)\n",
    "    val_loss, val_IoUs = segmentation.evaluate(dl_test, loss_fn, model)\n",
    "    print(epoch, f'{trn_loss:.4f}', f'{val_loss:.4f}', val_IoUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027baa75-0f08-4f45-8551-455d2d69f0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stenoses",
   "language": "python",
   "name": "stenoses"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
