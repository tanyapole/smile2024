{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45087e59-580d-46fb-bcb6-a3509425bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pickle, os, torch\n",
    "# from pathlib import Path\n",
    "# from PIL import Image\n",
    "# from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "# import torchvision\n",
    "# import torchvision.transforms as TF\n",
    "# import torchvision.transforms.v2 as TF2\n",
    "\n",
    "# from tqdm.auto import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "import utils, segmentation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5059538-77c9-47db-8a92-0406f8197d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = segmentation.SegmentationDataset('./stenoses_data/train/', 2)\n",
    "ds_test = segmentation.SegmentationDataset('./stenoses_data/test/', 2)\n",
    "\n",
    "batch_size = 8\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bafe610-5b73-42c4-aa8d-7411f5859734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl_train), len(dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea7a0dd-d609-4c39-b539-8c71bb65bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dbde329-58a2-4808-8d8d-4526aee4f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet18\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=2,                      # model output channels (number of classes in your dataset)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ebb2110-461d-4f16-b4fe-2b3211a47f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05d6daaf-7481-427f-baf1-25d24c8294b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0.\n",
    "for imgs, masks in dl_train:\n",
    "    w += masks.sum() / (masks.numel() * len(dl_train))\n",
    "loss_fn = nn.CrossEntropyLoss(weight=torch.Tensor([1 / (1-w), 1/ w])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd5cda3c-6418-4cae-9941-ee6d61387532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1524 0.3343 tensor([0.0193])\n",
      "1 0.0458 0.1384 tensor([0.0743])\n",
      "2 0.0329 0.0797 tensor([0.2065])\n",
      "3 0.0099 0.0599 tensor([0.3718])\n",
      "4 0.0115 0.1356 tensor([0.4679])\n",
      "5 0.0057 0.0765 tensor([0.4250])\n",
      "6 0.0053 0.0998 tensor([0.4504])\n",
      "7 0.0049 0.1408 tensor([0.5068])\n",
      "8 0.0039 0.0850 tensor([0.4850])\n",
      "9 0.0037 0.1979 tensor([0.5076])\n",
      "10 0.0044 0.2669 tensor([0.5244])\n",
      "11 0.0036 0.2974 tensor([0.5341])\n",
      "12 0.0034 0.1722 tensor([0.5702])\n",
      "13 0.0037 0.3034 tensor([0.5395])\n",
      "14 0.0029 0.1029 tensor([0.5147])\n",
      "15 0.0031 0.2141 tensor([0.5979])\n",
      "16 0.0029 0.1973 tensor([0.5651])\n",
      "17 0.0026 0.2019 tensor([0.5863])\n",
      "18 0.0026 0.2082 tensor([0.6056])\n",
      "19 0.0025 0.2655 tensor([0.6453])\n",
      "20 0.0025 0.2314 tensor([0.5976])\n",
      "21 0.0023 0.2352 tensor([0.6204])\n",
      "22 0.0023 0.2559 tensor([0.6186])\n",
      "23 0.0022 0.3349 tensor([0.6192])\n",
      "24 0.0022 0.2432 tensor([0.6294])\n",
      "25 0.0021 0.3590 tensor([0.6132])\n",
      "26 0.0021 0.3663 tensor([0.6115])\n",
      "27 0.0020 0.3706 tensor([0.6164])\n",
      "28 0.0019 0.3451 tensor([0.6219])\n",
      "29 0.0020 0.4271 tensor([0.6135])\n",
      "30 0.0021 0.3217 tensor([0.6408])\n",
      "31 0.0020 0.3100 tensor([0.6209])\n",
      "32 0.0019 0.3637 tensor([0.6494])\n",
      "33 0.0018 0.4039 tensor([0.6353])\n",
      "34 0.0019 0.3596 tensor([0.6417])\n",
      "35 0.0018 0.5011 tensor([0.6131])\n",
      "36 0.0018 0.2419 tensor([0.6205])\n",
      "37 0.0017 0.3196 tensor([0.6362])\n",
      "38 0.0017 0.3374 tensor([0.6232])\n",
      "39 0.0019 0.0481 tensor([0.3102])\n",
      "40 0.0025 0.3029 tensor([0.6117])\n",
      "41 0.0018 0.2795 tensor([0.6000])\n",
      "42 0.0018 0.3598 tensor([0.6478])\n",
      "43 0.0018 0.3449 tensor([0.6400])\n",
      "44 0.0017 0.4443 tensor([0.6216])\n",
      "45 0.0020 0.2688 tensor([0.6234])\n",
      "46 0.0019 0.4134 tensor([0.6426])\n",
      "47 0.0017 0.3833 tensor([0.6284])\n",
      "48 0.0016 0.3756 tensor([0.6243])\n",
      "49 0.0017 0.4236 tensor([0.6552])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    trn_loss = utils.train(dl_train, loss_fn, model, optimizer)\n",
    "    val_loss, val_IoUs = segmentation.evaluate(dl_test, loss_fn, model)\n",
    "    print(epoch, f'{trn_loss:.4f}', f'{val_loss:.4f}', val_IoUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027baa75-0f08-4f45-8551-455d2d69f0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stenoses",
   "language": "python",
   "name": "stenoses"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
