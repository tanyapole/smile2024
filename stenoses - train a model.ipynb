{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45087e59-580d-46fb-bcb6-a3509425bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils, segmentation, presentation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5059538-77c9-47db-8a92-0406f8197d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = segmentation.SegmentationDataset('./cut_stenoses_data/train/', 2)\n",
    "ds_test = segmentation.SegmentationDataset('./cut_stenoses_data/test/', 2)\n",
    "\n",
    "batch_size = 8\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bafe610-5b73-42c4-aa8d-7411f5859734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl_train), len(dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea7a0dd-d609-4c39-b539-8c71bb65bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dbde329-58a2-4808-8d8d-4526aee4f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = presentation.create_model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ebb2110-461d-4f16-b4fe-2b3211a47f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = presentation.create_optimizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05d6daaf-7481-427f-baf1-25d24c8294b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = 0.\n",
    "# for imgs, masks in dl_train:\n",
    "#     w += masks.sum() / (masks.numel() * len(dl_train))\n",
    "# loss_fn = nn.CrossEntropyLoss(weight=torch.Tensor([1 / (1-w), 1/ w])).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd5cda3c-6418-4cae-9941-ee6d61387532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0259 0.0160 tensor([0.])\n",
      "1 0.0064 0.0142 tensor([0.])\n",
      "2 0.0055 0.0140 tensor([0.])\n",
      "3 0.0049 0.0113 tensor([0.4794])\n",
      "4 0.0045 0.0156 tensor([0.3883])\n",
      "5 0.0041 0.0134 tensor([0.4685])\n",
      "6 0.0038 0.0122 tensor([0.5148])\n",
      "7 0.0035 0.0146 tensor([0.4791])\n",
      "8 0.0033 0.0141 tensor([0.5053])\n",
      "9 0.0031 0.0147 tensor([0.4994])\n",
      "10 0.0029 0.0135 tensor([0.5317])\n",
      "11 0.0027 0.0137 tensor([0.5394])\n",
      "12 0.0026 0.0155 tensor([0.5234])\n",
      "13 0.0025 0.0117 tensor([0.5745])\n",
      "14 0.0024 0.0138 tensor([0.5499])\n",
      "15 0.0022 0.0140 tensor([0.5475])\n",
      "16 0.0022 0.0130 tensor([0.5689])\n",
      "17 0.0021 0.0141 tensor([0.5580])\n",
      "18 0.0021 0.0130 tensor([0.5765])\n",
      "19 0.0019 0.0139 tensor([0.5622])\n",
      "20 0.0018 0.0132 tensor([0.5748])\n",
      "21 0.0018 0.0129 tensor([0.5824])\n",
      "22 0.0018 0.0118 tensor([0.6150])\n",
      "23 0.0017 0.0138 tensor([0.5713])\n",
      "24 0.0016 0.0139 tensor([0.5765])\n",
      "25 0.0016 0.0136 tensor([0.5788])\n",
      "26 0.0015 0.0133 tensor([0.5913])\n",
      "27 0.0015 0.0121 tensor([0.6054])\n",
      "28 0.0014 0.0131 tensor([0.5934])\n",
      "29 0.0014 0.0134 tensor([0.5918])\n",
      "30 0.0014 0.0129 tensor([0.6005])\n",
      "31 0.0013 0.0143 tensor([0.5852])\n",
      "32 0.0013 0.0124 tensor([0.6081])\n",
      "33 0.0013 0.0142 tensor([0.5864])\n",
      "34 0.0012 0.0159 tensor([0.5698])\n",
      "35 0.0012 0.0146 tensor([0.5908])\n",
      "36 0.0012 0.0146 tensor([0.5912])\n",
      "37 0.0011 0.0136 tensor([0.6039])\n",
      "38 0.0012 0.0138 tensor([0.6072])\n",
      "39 0.0011 0.0137 tensor([0.6050])\n",
      "40 0.0011 0.0142 tensor([0.5966])\n",
      "41 0.0012 0.0136 tensor([0.6025])\n",
      "42 0.0011 0.0127 tensor([0.6183])\n",
      "43 0.0010 0.0136 tensor([0.6094])\n",
      "44 0.0010 0.0139 tensor([0.6044])\n",
      "45 0.0010 0.0143 tensor([0.5980])\n",
      "46 0.0010 0.0142 tensor([0.6062])\n",
      "47 0.0010 0.0114 tensor([0.6317])\n",
      "48 0.0010 0.0133 tensor([0.6189])\n",
      "49 0.0009 0.0130 tensor([0.6185])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    trn_loss = utils.train(dl_train, loss_fn, model, optimizer)\n",
    "    val_loss, val_IoUs = segmentation.evaluate(dl_test, loss_fn, model)\n",
    "    print(epoch, f'{trn_loss:.4f}', f'{val_loss:.4f}', val_IoUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027baa75-0f08-4f45-8551-455d2d69f0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stenoses",
   "language": "python",
   "name": "stenoses"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
